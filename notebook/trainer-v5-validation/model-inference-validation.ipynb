{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of RWKV v5 model inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rwkv in /home/picocreator/anaconda3/envs/rwkv-exp/lib/python3.11/site-packages (0.8.16)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/picocreator/anaconda3/envs/rwkv-exp/lib/python3.11/site-packages (from rwkv) (0.13.3)\n"
     ]
    }
   ],
   "source": [
    "# Update the RWKV pip package, found here : https://pypi.org/project/rwkv/\n",
    "!python3 -m pip install --upgrade rwkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK_DIR: /home/picocreator/rwkv-proj/infctx-dev/notebook/trainer-v5-validation\n",
      "TRAINER_DIR: /home/picocreator/rwkv-proj/infctx-dev/RWKV-v5\n",
      "PROJECT_DIR: /home/picocreator/rwkv-proj/infctx-dev\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_MODE=\"cpu\"\n",
    "INFERENCE_TYPE=\"fp32\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘RWKV-5-World-1B5-v2-20231025-ctx4096.pth’ already there; not retrieving.\n",
      "\n",
      "Echo-A-1B5-Init.pth\t L32-D2560-neox-init.pth\n",
      "L24-D2048-init.pth\t L32-D4096-neox-init.pth\n",
      "L24-D2048-neox-init.pth  RWKV-5-World-1B5-v2-20231025-ctx4096.pth\n",
      "/home/picocreator/rwkv-proj/infctx-dev/model\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../../model/\n",
    "!cd ../../model/ && wget -nc \"https://huggingface.co/BlinkDL/rwkv-5-world/resolve/8eb0273bd6935fa310c57532637d93d055d72f05/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\"\n",
    "!cd ../../model/ && ls\n",
    "!cd ../../model/ && pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference code inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 0\n",
      "\n",
      "Loading /home/picocreator/rwkv-proj/infctx-dev/model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: (total 24+1=25 layers)\n",
      "* cpu [float32, float32], store 25 layers\n",
      "0-cpu-float32-float32 1-cpu-float32-float32 2-cpu-float32-float32 3-cpu-float32-float32 4-cpu-float32-float32 5-cpu-float32-float32 6-cpu-float32-float32 7-cpu-float32-float32 8-cpu-float32-float32 9-cpu-float32-float32 10-cpu-float32-float32 11-cpu-float32-float32 12-cpu-float32-float32 13-cpu-float32-float32 14-cpu-float32-float32 15-cpu-float32-float32 16-cpu-float32-float32 17-cpu-float32-float32 18-cpu-float32-float32 19-cpu-float32-float32 20-cpu-float32-float32 21-cpu-float32-float32 22-cpu-float32-float32 23-cpu-float32-float32 24-cpu-float32-float32 \n",
      "emb.weight                        f32      cpu  65536  2048 \n",
      "blocks.0.ln1.weight               f32      cpu   2048       \n",
      "blocks.0.ln1.bias                 f32      cpu   2048       \n",
      "blocks.0.ln2.weight               f32      cpu   2048       \n",
      "blocks.0.ln2.bias                 f32      cpu   2048       \n",
      "blocks.0.att.time_mix_k           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_v           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_r           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_g           f32      cpu   2048       \n",
      "blocks.0.att.time_decay           f32      cpu     32    64 \n",
      "blocks.0.att.time_first           f32      cpu     32    64 \n",
      "blocks.0.att.receptance.weight    f32      cpu   2048  2048 \n",
      "blocks.0.att.key.weight           f32      cpu   2048  2048 \n",
      "blocks.0.att.value.weight         f32      cpu   2048  2048 \n",
      "blocks.0.att.output.weight        f32      cpu   2048  2048 \n",
      "blocks.0.att.gate.weight          f32      cpu   2048  2048 \n",
      "blocks.0.att.ln_x.weight          f32      cpu   2048       \n",
      "blocks.0.att.ln_x.bias            f32      cpu   2048       \n",
      "blocks.0.ffn.time_mix_k           f32      cpu   2048       \n",
      "blocks.0.ffn.time_mix_r           f32      cpu   2048       \n",
      "blocks.0.ffn.key.weight           f32      cpu   2048  7168 \n",
      "blocks.0.ffn.receptance.weight    f32      cpu   2048  2048 \n",
      "blocks.0.ffn.value.weight         f32      cpu   7168  2048 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight              f32      cpu   2048       \n",
      "blocks.23.ln1.bias                f32      cpu   2048       \n",
      "blocks.23.ln2.weight              f32      cpu   2048       \n",
      "blocks.23.ln2.bias                f32      cpu   2048       \n",
      "blocks.23.att.time_mix_k          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_v          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_r          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_g          f32      cpu   2048       \n",
      "blocks.23.att.time_decay          f32      cpu     32    64 \n",
      "blocks.23.att.time_first          f32      cpu     32    64 \n",
      "blocks.23.att.receptance.weight   f32      cpu   2048  2048 \n",
      "blocks.23.att.key.weight          f32      cpu   2048  2048 \n",
      "blocks.23.att.value.weight        f32      cpu   2048  2048 \n",
      "blocks.23.att.output.weight       f32      cpu   2048  2048 \n",
      "blocks.23.att.gate.weight         f32      cpu   2048  2048 \n",
      "blocks.23.att.ln_x.weight         f32      cpu   2048       \n",
      "blocks.23.att.ln_x.bias           f32      cpu   2048       \n",
      "blocks.23.ffn.time_mix_k          f32      cpu   2048       \n",
      "blocks.23.ffn.time_mix_r          f32      cpu   2048       \n",
      "blocks.23.ffn.key.weight          f32      cpu   2048  7168 \n",
      "blocks.23.ffn.receptance.weight   f32      cpu   2048  2048 \n",
      "blocks.23.ffn.value.weight        f32      cpu   7168  2048 \n",
      "ln_out.weight                     f32      cpu   2048       \n",
      "ln_out.bias                       f32      cpu   2048       \n",
      "head.weight                       f32      cpu   2048 65536 \n",
      "\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "The researchers, who were led by Dr. David Doubilet, a photographer and filmmaker, were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
      "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
      "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
      "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
      "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '0' # '1' to compile CUDA kernel (10x faster), requires c++ compiler & cuda libraries\n",
    "\n",
    "from rwkv.model import RWKV\n",
    "from rwkv.utils import PIPELINE, PIPELINE_ARGS\n",
    "\n",
    "model = RWKV(model=os.path.join(PROJECT_DIR, \"model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\"), strategy='cpu fp32')\n",
    "pipeline = PIPELINE(model, \"rwkv_vocab_v20230424\") # Using the world tokenizer\n",
    "\n",
    "ctx = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n",
    "print(ctx, end='')\n",
    "\n",
    "def my_print(s):\n",
    "    print(s, end='', flush=True)\n",
    "\n",
    "# # For alpha_frequency and alpha_presence, see \"Frequency and presence penalties\":\n",
    "# # https://platform.openai.com/docs/api-reference/parameter-details\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# We use top_k = 1 to effectively always take the highest choice token\n",
    "args = PIPELINE_ARGS(temperature = 0.5, top_p = 0.7, top_k = 1, # top_k = 0 then ignore\n",
    "                    #  alpha_frequency = 0.25,\n",
    "                    #  alpha_presence = 0.25,\n",
    "                    #  alpha_decay = 0.996, # gradually decay the penalty\n",
    "                     token_ban = [0], # ban the generation of some tokens\n",
    "                     token_stop = [], # stop generation whenever you see any token here\n",
    "                     chunk_len = 256) # split input into chunks to save VRAM (shorter -> slower)\n",
    "\n",
    "pipeline.generate(ctx, token_count=200, args=args, callback=my_print)\n",
    "print('\\n')\n",
    "\n",
    "# out, state = model.forward([187, 510, 1563, 310, 247], None)\n",
    "# print(out.detach().cpu().numpy())                   # get logits\n",
    "# out, state = model.forward([187, 510], None)\n",
    "# out, state = model.forward([1563], state)           # RNN has state (use deepcopy to clone states)\n",
    "# out, state = model.forward([310, 247], state)\n",
    "# print(out.detach().cpu().numpy())                   # same result as above\n",
    "# print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected result should be\n",
    "\n",
    "```\n",
    "\n",
    "The researchers, who were led by Dr. David Doubilet, a photographer and filmmaker, were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
    "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
    "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
    "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for over two hours, and they were able to capture the dragons in their natural habitat.\n",
    "The researchers were able to capture the dragons in their natural habitat. The team was able to film the dragons for\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV infctx trainer, in inference mode\n",
    "\n",
    "Should match the above result (200 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-28 13:25:29,225] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/picocreator/rwkv-proj/infctx-dev/RWKV-v5/./dragon_test.py\", line 52, in <module>\n",
      "    model = SimpleRWKV(MODEL_PATH, device=DEVICE)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/rwkv-proj/infctx-dev/RWKV-v5/src/model.py\", line 1420, in __init__\n",
      "    self.model = RWKV(**model_config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/picocreator/rwkv-proj/infctx-dev/RWKV-v5/src/model.py\", line 670, in __init__\n",
      "    self.load_state_dict(model_weights)\n",
      "  File \"/home/picocreator/anaconda3/envs/rwkv-exp/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
      "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
      "RuntimeError: Error(s) in loading state_dict for RWKV:\n",
      "\tsize mismatch for blocks.0.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.0.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.1.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.1.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.2.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.2.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.3.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.3.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.4.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.4.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.5.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.5.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.6.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.6.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.7.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.7.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.8.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.8.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.9.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.9.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.10.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.10.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.11.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.11.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.12.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.12.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.13.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.13.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.14.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.14.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.15.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.15.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.16.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.16.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.17.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.17.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.18.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.18.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.19.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.19.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.20.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.20.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.21.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.21.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.22.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.22.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.23.att.time_decay: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n",
      "\tsize mismatch for blocks.23.att.time_faaaa: copying a param with shape torch.Size([32, 64]) from checkpoint, the shape in current model is torch.Size([32]).\n"
     ]
    }
   ],
   "source": [
    "# Run the reference implementation\n",
    "!cd $TRAINER_DIR && python3 ./dragon_test.py \"../model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\" \"ref\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
